{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentiment ML 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import *\n",
    "from word_tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cette', 'jean', 'contre', 'être', 'lettre', 'tous', 'européens', 'même', 'bien', 'politique', 'français', 'ils', 'tout', 'faire', 'comme', 'lui', 'jaunes', 'président', 'sont', 'gilets', 'nous', 'raffarin', 'mais', 'fait', 'renaissance', 'tribune', 'européennes', 'par', 'son', 'france', 'via', 'plus', 'avec', 'sur', 'européenne', 'europe', 'aux', 'vous', 'dans', 'emmanuel', 'qui', 'pas', 'que', 'une', 'des', 'pour', 'est', 'les', '', 'macron']\n"
     ]
    }
   ],
   "source": [
    "from word_tools import make_bagofwords\n",
    "\n",
    "nb_words = 10000\n",
    "\n",
    "bow = make_bagofwords(\"corpus_ready.data\", nb_words)\n",
    "print(bow[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_tools import vectorize_tweets\n",
    "vect = vectorize_tweets(\"tw_db_prepared.data\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keys = [k for k in vect]\n",
    "print(np.shape(vect[keys[0]]['vectorized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(np.max([np.shape(vect[k]['vectorized'])[0] for k in vect]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8700    0 8086 8601 8705 8603 1643 8696    0 7388 8250 8689 8700 8675\n",
      " 8672 8696 8244 1979 8630 7623 8700 5841 8696 8703    0 7346 8700 8577\n",
      " 7245 8701 8703 3927 8403 1735 8241 8704    0    0    0    0    0    0\n",
      "    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_data(vectsdict):\n",
    "    import numpy as np\n",
    "    vects = []\n",
    "    labels = []\n",
    "    \n",
    "    for key in vectsdict :\n",
    "        if not np.all(vectsdict[key]['label'] == 0) :\n",
    "            vects.append(vectsdict[key]['vectorized'])\n",
    "            labels.append(vectsdict[key]['label'])\n",
    "    return np.array(vects), np.array(labels)\n",
    "\n",
    "def decode_output(out_array) :\n",
    "    if out_array[0] == np.max(out_array) :\n",
    "        return \"irr\", np.max(out_array)\n",
    "    elif out_array[1] == np.max(out_array) :\n",
    "        return \"neg\", np.max(out_array)\n",
    "    elif out_array[2] == np.max(out_array) :\n",
    "        return \"neu\",np.max(out_array)\n",
    "    elif out_array[3] == np.max(out_array) :\n",
    "        return \"pos\",np.max(out_array)\n",
    "    else :\n",
    "        return \"err\",0\n",
    "    \n",
    "data, labels = extract_data(vect)\n",
    "\n",
    "\n",
    "percentage_train = 0.8\n",
    "borne = int(percentage_train*len(data))\n",
    "X_train = data[:borne]\n",
    "Y_train = labels[:borne]\n",
    "X_test = data[borne:]\n",
    "Y_test = labels[borne:]\n",
    "\n",
    "print(X_train[0])\n",
    "input_l = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "806/806 [==============================] - 3s 3ms/step - loss: 1.2224 - acc: 0.5037\n",
      "Epoch 2/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.1515 - acc: 0.5285\n",
      "Epoch 3/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.1478 - acc: 0.5285\n",
      "Epoch 4/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.1512 - acc: 0.5285\n",
      "Epoch 5/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.1431 - acc: 0.5285\n",
      "Epoch 6/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.1202 - acc: 0.5099\n",
      "Epoch 7/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 1.0116 - acc: 0.5782\n",
      "Epoch 8/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.8604 - acc: 0.6352\n",
      "Epoch 9/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.7118 - acc: 0.7097\n",
      "Epoch 10/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.6224 - acc: 0.7506\n",
      "Epoch 11/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.6146 - acc: 0.7605\n",
      "Epoch 12/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.4734 - acc: 0.8176\n",
      "Epoch 13/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.4361 - acc: 0.8201\n",
      "Epoch 14/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.3760 - acc: 0.8375\n",
      "Epoch 15/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.3121 - acc: 0.8561\n",
      "Epoch 16/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.2786 - acc: 0.8933\n",
      "Epoch 17/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.3648 - acc: 0.8660\n",
      "Epoch 18/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.2706 - acc: 0.9020\n",
      "Epoch 19/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.2390 - acc: 0.9194\n",
      "Epoch 20/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.2074 - acc: 0.9330\n",
      "Epoch 21/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1747 - acc: 0.9380\n",
      "Epoch 22/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1652 - acc: 0.9404\n",
      "Epoch 23/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1495 - acc: 0.9491\n",
      "Epoch 24/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1358 - acc: 0.9467\n",
      "Epoch 25/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1190 - acc: 0.9553\n",
      "Epoch 26/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.0850 - acc: 0.9789\n",
      "Epoch 27/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.0871 - acc: 0.9739\n",
      "Epoch 28/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.0793 - acc: 0.9764\n",
      "Epoch 29/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1059 - acc: 0.9615\n",
      "Epoch 30/30\n",
      "806/806 [==============================] - 2s 2ms/step - loss: 0.1057 - acc: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74dc3229e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim,input_length =input_l))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "# compile the model\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# print(model.summary())\n",
    "batch = 200\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6039603960396039\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# loss, accuracy = model.evaluate(X_train, Y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet is evaluated neg\n"
     ]
    }
   ],
   "source": [
    "test = \"Aux chiottes macron tu as fais du mal aux gilets jaunes\"\n",
    "\n",
    "test_vect = vectorize_tweet(test, \"pos\", bow, input_l)\n",
    "v = np.array(test_vect['vectorized'])\n",
    "v = v.reshape((1,input_l))\n",
    "\n",
    "res = model.predict([v])[0]\n",
    "out = decode_output(res)\n",
    "print(\"tweet is evaluated \" + out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revoir les taux votes par csp niveau revenu lors des législatives tant que les classesmoyennes sup sont pas lessivées comme les gilets jaunes par macron président des ultras riches lrem sera devant attendre ans désindexation retraite ', 'vous êtes une grande naïveté monsieur ensorcelé par gourou soudaine empathie pour ceux qui sont rien vous surprend pas cette période approchant les élections européennes macron essaie soigner son image arrogant hors sol ', 'macron fera jamais rien qui puisse choquer les musulmans les islamistes car est une part importante son électorat trahison ', 'dictature régime politique dans lequel tous les pouvoirs sont entre les mains une seule personne oui effectivement macron est pas seul ceux qui ont intérêt que reste comme aide bcp vrai décide pas chose ', 'affaire macron benalla réponse nos détracteurs via ', 'est macron qui est complice pire', 'bref jsuis vener cause vos histoires plus macron fait des bottle flip pendant que samedi peux plus sortir chez moi parce que plus bus cause des gilets jaunes ', 'vision européenne macron est celle balladur bref ump chez mais après les élections une fois pouvoir frexit', 'emmanuel macron veut instaurer une fiscalité taxe carbone liée aux cours mondiaux ', 'derrière les soutiens mlp surtout ceux qui appartiennent milieu journalistique général est pour sauver macron nous connaissons maintenant stratégie des médias ']\n"
     ]
    }
   ],
   "source": [
    "from parse import sample_data\n",
    "testset = sample_data(\"tw_db_prepared.data\", 10)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revoir les taux votes par csp niveau revenu lors des législatives tant que les classesmoyennes sup sont pas lessivées comme les gilets jaunes par macron président des ultras riches lrem sera devant attendre ans désindexation retraite \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "vous êtes une grande naïveté monsieur ensorcelé par gourou soudaine empathie pour ceux qui sont rien vous surprend pas cette période approchant les élections européennes macron essaie soigner son image arrogant hors sol \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "macron fera jamais rien qui puisse choquer les musulmans les islamistes car est une part importante son électorat trahison \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "dictature régime politique dans lequel tous les pouvoirs sont entre les mains une seule personne oui effectivement macron est pas seul ceux qui ont intérêt que reste comme aide bcp vrai décide pas chose \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "affaire macron benalla réponse nos détracteurs via \n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "est macron qui est complice pire\n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "bref jsuis vener cause vos histoires plus macron fait des bottle flip pendant que samedi peux plus sortir chez moi parce que plus bus cause des gilets jaunes \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "vision européenne macron est celle balladur bref ump chez mais après les élections une fois pouvoir frexit\n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "emmanuel macron veut instaurer une fiscalité taxe carbone liée aux cours mondiaux \n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "derrière les soutiens mlp surtout ceux qui appartiennent milieu journalistique général est pour sauver macron nous connaissons maintenant stratégie des médias \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tw in testset :\n",
    "    vec = vectorize_tweet(tw,'???', bow, input_l)\n",
    "    print(vec['text'])\n",
    "    res = model.predict(vec['vectorized'].reshape((1,input_l)))[0]\n",
    "    out = decode_output(res)\n",
    "    print(\"tweet is evaluated \" + out[0] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
