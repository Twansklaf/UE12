{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentiment ML 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import *\n",
    "from word_tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contre', 'être', 'européens', 'ont', 'tous', 'grand', 'même', 'politique', 'bien', 'français', 'président', 'lui', 'ils', 'faire', 'tout', 'comme', 'sont', 'raffarin', 'gilets', 'jaunes', 'renaissance', 'tribune', 'http', 'nous', 'fait', 'mais', 'via', 'européennes', 'france', 'par', 'son', 'plus', 'européenne', 'avec', 'sur', 'aux', 'europe', 'vous', 'dans', 'emmanuel', 'qui', 'pas', 'que', 'une', 'des', 'pour', 'est', 'les', '', 'macron']\n"
     ]
    }
   ],
   "source": [
    "from word_tools import make_bagofwords\n",
    "\n",
    "nb_words = 10000\n",
    "\n",
    "bow = make_bagofwords(\"data/corpus.data\", nb_words)\n",
    "print(bow[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_tools import vectorize_tweets\n",
    "vect = vectorize_tweets(\"data/corpus.data\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keys = [k for k in vect]\n",
    "print(np.shape(vect[keys[0]]['vectorized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(np.max([np.shape(vect[k]['vectorized'])[0] for k in vect]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9989 9999 9744 9992 9808 9982    0 8347 7170 9975 9892 9991 4365 9997\n",
      " 8083 7171 9990    0 9984 9942 6223 9892 9991 7172 9751 9901 9734    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_data(vectsdict):\n",
    "    import numpy as np\n",
    "    vects = []\n",
    "    labels = []\n",
    "    \n",
    "    for key in vectsdict :\n",
    "        if not np.all(vectsdict[key]['label'] == 0) :\n",
    "            vects.append(vectsdict[key]['vectorized'])\n",
    "            labels.append(vectsdict[key]['label'])\n",
    "    return np.array(vects), np.array(labels)\n",
    "\n",
    "def decode_output(out_array) :\n",
    "    if out_array[0] == np.max(out_array) :\n",
    "        return \"irr\", np.max(out_array)\n",
    "    elif out_array[1] == np.max(out_array) :\n",
    "        return \"neg\", np.max(out_array)\n",
    "    elif out_array[2] == np.max(out_array) :\n",
    "        return \"neu\",np.max(out_array)\n",
    "    elif out_array[3] == np.max(out_array) :\n",
    "        return \"pos\",np.max(out_array)\n",
    "    else :\n",
    "        return \"err\",0\n",
    "    \n",
    "data, labels = extract_data(vect)\n",
    "\n",
    "\n",
    "percentage_train = 0.8\n",
    "borne = int(percentage_train*len(data))\n",
    "X_train = data[:borne]\n",
    "Y_train = labels[:borne]\n",
    "X_test = data[borne:]\n",
    "Y_test = labels[borne:]\n",
    "\n",
    "print(X_train[0])\n",
    "input_l = len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3998/3998 [==============================] - 7s 2ms/step - loss: 1.1748 - acc: 0.4572\n",
      "Epoch 2/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 1.1161 - acc: 0.4885\n",
      "Epoch 3/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 1.1114 - acc: 0.4877\n",
      "Epoch 4/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 1.1108 - acc: 0.4882\n",
      "Epoch 5/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 1.0875 - acc: 0.5145\n",
      "Epoch 6/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 0.9948 - acc: 0.6333\n",
      "Epoch 7/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 0.9247 - acc: 0.6856\n",
      "Epoch 8/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 0.8424 - acc: 0.7216\n",
      "Epoch 9/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 0.7442 - acc: 0.7534\n",
      "Epoch 10/10\n",
      "3998/3998 [==============================] - 6s 2ms/step - loss: 0.6892 - acc: 0.7771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff367780e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim,input_length =input_l))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "# print(model.summary())\n",
    "# compile the model\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# print(model.summary())\n",
    "batch = 200\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# loss, accuracy = model.evaluate(X_train, Y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet is evaluated neu\n"
     ]
    }
   ],
   "source": [
    "test = \"Aux chiottes macron tu as fais du mal aux gilets jaunes\"\n",
    "\n",
    "test_vect = vectorize_tweet(test, \"pos\", bow, input_l)\n",
    "v = np.array(test_vect['vectorized'])\n",
    "v = v.reshape((1,input_l))\n",
    "\n",
    "res = model.predict([v])[0]\n",
    "out = decode_output(res)\n",
    "print(\"tweet is evaluated \" + out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revoir les taux votes par csp niveau revenu lors des législatives tant que les classesmoyennes sup sont pas lessivées comme les gilets jaunes par macron président des ultras riches lrem sera devant attendre ans désindexation retraite ', 'vous êtes une grande naïveté monsieur ensorcelé par gourou soudaine empathie pour ceux qui sont rien vous surprend pas cette période approchant les élections européennes macron essaie soigner son image arrogant hors sol ', 'macron fera jamais rien qui puisse choquer les musulmans les islamistes car est une part importante son électorat trahison ', 'dictature régime politique dans lequel tous les pouvoirs sont entre les mains une seule personne oui effectivement macron est pas seul ceux qui ont intérêt que reste comme aide bcp vrai décide pas chose ', 'affaire macron benalla réponse nos détracteurs via ', 'est macron qui est complice pire', 'bref jsuis vener cause vos histoires plus macron fait des bottle flip pendant que samedi peux plus sortir chez moi parce que plus bus cause des gilets jaunes ', 'vision européenne macron est celle balladur bref ump chez mais après les élections une fois pouvoir frexit', 'emmanuel macron veut instaurer une fiscalité taxe carbone liée aux cours mondiaux ', 'derrière les soutiens mlp surtout ceux qui appartiennent milieu journalistique général est pour sauver macron nous connaissons maintenant stratégie des médias ']\n"
     ]
    }
   ],
   "source": [
    "from parse import sample_data\n",
    "testset = sample_data(\"tw_db_prepared.data\", 10)\n",
    "print(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revoir les taux votes par csp niveau revenu lors des législatives tant que les classesmoyennes sup sont pas lessivées comme les gilets jaunes par macron président des ultras riches lrem sera devant attendre ans désindexation retraite \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "vous êtes une grande naïveté monsieur ensorcelé par gourou soudaine empathie pour ceux qui sont rien vous surprend pas cette période approchant les élections européennes macron essaie soigner son image arrogant hors sol \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "macron fera jamais rien qui puisse choquer les musulmans les islamistes car est une part importante son électorat trahison \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "dictature régime politique dans lequel tous les pouvoirs sont entre les mains une seule personne oui effectivement macron est pas seul ceux qui ont intérêt que reste comme aide bcp vrai décide pas chose \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "affaire macron benalla réponse nos détracteurs via \n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "est macron qui est complice pire\n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "bref jsuis vener cause vos histoires plus macron fait des bottle flip pendant que samedi peux plus sortir chez moi parce que plus bus cause des gilets jaunes \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n",
      "vision européenne macron est celle balladur bref ump chez mais après les élections une fois pouvoir frexit\n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "emmanuel macron veut instaurer une fiscalité taxe carbone liée aux cours mondiaux \n",
      "tweet is evaluated neu\n",
      "\n",
      "\n",
      "derrière les soutiens mlp surtout ceux qui appartiennent milieu journalistique général est pour sauver macron nous connaissons maintenant stratégie des médias \n",
      "tweet is evaluated neg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tw in testset :\n",
    "    vec = vectorize_tweet(tw,'???', bow, input_l)\n",
    "    print(vec['text'])\n",
    "    res = model.predict(vec['vectorized'].reshape((1,input_l)))[0]\n",
    "    out = decode_output(res)\n",
    "    print(\"tweet is evaluated \" + out[0] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0.3, 0.2, 0.7, 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
