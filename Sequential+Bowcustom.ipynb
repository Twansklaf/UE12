{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sentiment ML 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import *\n",
    "from word_tools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contre', 'être', 'européens', 'ont', 'tous', 'grand', 'même', 'politique', 'bien', 'français', 'président', 'lui', 'ils', 'faire', 'tout', 'comme', 'sont', 'raffarin', 'gilets', 'jaunes', 'renaissance', 'tribune', 'http', 'nous', 'fait', 'mais', 'via', 'européennes', 'france', 'par', 'son', 'plus', 'européenne', 'avec', 'sur', 'aux', 'europe', 'vous', 'dans', 'emmanuel', 'qui', 'pas', 'que', 'une', 'des', 'pour', 'est', 'les', '', 'macron']\n"
     ]
    }
   ],
   "source": [
    "from word_tools import make_bagofwords\n",
    "\n",
    "nb_words = 10000\n",
    "\n",
    "bow = make_bagofwords(\"data/corpus.data\", 10000)\n",
    "print(bow[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_tools import vectorize_tweets\n",
    "vect = vectorize_tweets(\"data/corpus.data\", bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keys = [k for k in vect]\n",
    "\n",
    "input_len = np.shape(vect[keys[0]]['vectorized'])[0]\n",
    "\n",
    "print(np.shape(vect[keys[0]]['vectorized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9989 9999 9744 9992 9808 9982    0 8347 7170 9975 9892 9991 4365 9997\n",
      " 8083 7171 9990    0 9984 9942 6223 9892 9991 7172 9751 9901 9734    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_data(vectsdict):\n",
    "    import numpy as np\n",
    "    vects = []\n",
    "    labels = []\n",
    "    \n",
    "    for key in vectsdict :\n",
    "        if not np.all(vectsdict[key]['label'] == 0) :\n",
    "            vects.append(vectsdict[key]['vectorized'])\n",
    "            labels.append(vectsdict[key]['label'])\n",
    "    return np.array(vects), np.array(labels)\n",
    "\n",
    "def decode_output(out_array) :\n",
    "    if out_array[0] == np.max(out_array) :\n",
    "        return \"irr\", np.max(out_array)\n",
    "    elif out_array[1] == np.max(out_array) :\n",
    "        return \"neg\", np.max(out_array)\n",
    "    elif out_array[2] == np.max(out_array) :\n",
    "        return \"neu\",np.max(out_array)\n",
    "    elif out_array[3] == np.max(out_array) :\n",
    "        return \"pos\",np.max(out_array)\n",
    "    else :\n",
    "        return \"err\",0\n",
    "    \n",
    "data, labels = extract_data(vect)\n",
    "\n",
    "\n",
    "percentage_train = 0.8\n",
    "borne = int(percentage_train*len(data))\n",
    "X_train = data[:borne]\n",
    "Y_train = labels[:borne]\n",
    "X_test = data[borne:]\n",
    "Y_test = labels[borne:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "3998/3998 [==============================] - 0s 57us/step - loss: 0.6521 - acc: 0.7067\n",
      "Epoch 2/70\n",
      "3998/3998 [==============================] - 0s 53us/step - loss: 0.5110 - acc: 0.7669\n",
      "Epoch 3/70\n",
      "3998/3998 [==============================] - 0s 47us/step - loss: 0.4559 - acc: 0.7842\n",
      "Epoch 4/70\n",
      "3998/3998 [==============================] - 0s 32us/step - loss: 0.4395 - acc: 0.7999\n",
      "Epoch 5/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.4200 - acc: 0.8189\n",
      "Epoch 6/70\n",
      "3998/3998 [==============================] - 0s 28us/step - loss: 0.3983 - acc: 0.8344\n",
      "Epoch 7/70\n",
      "3998/3998 [==============================] - 0s 29us/step - loss: 0.3767 - acc: 0.8446\n",
      "Epoch 8/70\n",
      "3998/3998 [==============================] - 0s 29us/step - loss: 0.3565 - acc: 0.8569\n",
      "Epoch 9/70\n",
      "3998/3998 [==============================] - 0s 30us/step - loss: 0.3380 - acc: 0.8674\n",
      "Epoch 10/70\n",
      "3998/3998 [==============================] - 0s 26us/step - loss: 0.3200 - acc: 0.8774\n",
      "Epoch 11/70\n",
      "3998/3998 [==============================] - 0s 23us/step - loss: 0.3028 - acc: 0.8864\n",
      "Epoch 12/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.2865 - acc: 0.8964\n",
      "Epoch 13/70\n",
      "3998/3998 [==============================] - 0s 23us/step - loss: 0.2706 - acc: 0.9028\n",
      "Epoch 14/70\n",
      "3998/3998 [==============================] - 0s 25us/step - loss: 0.2552 - acc: 0.9131\n",
      "Epoch 15/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.2409 - acc: 0.9187\n",
      "Epoch 16/70\n",
      "3998/3998 [==============================] - 0s 23us/step - loss: 0.2274 - acc: 0.9240\n",
      "Epoch 17/70\n",
      "3998/3998 [==============================] - 0s 24us/step - loss: 0.2146 - acc: 0.9295\n",
      "Epoch 18/70\n",
      "3998/3998 [==============================] - 0s 29us/step - loss: 0.2025 - acc: 0.9346\n",
      "Epoch 19/70\n",
      "3998/3998 [==============================] - 0s 50us/step - loss: 0.1914 - acc: 0.9384\n",
      "Epoch 20/70\n",
      "3998/3998 [==============================] - 0s 41us/step - loss: 0.1810 - acc: 0.9428\n",
      "Epoch 21/70\n",
      "3998/3998 [==============================] - 0s 24us/step - loss: 0.1712 - acc: 0.9465\n",
      "Epoch 22/70\n",
      "3998/3998 [==============================] - 0s 25us/step - loss: 0.1621 - acc: 0.9506\n",
      "Epoch 23/70\n",
      "3998/3998 [==============================] - 0s 25us/step - loss: 0.1537 - acc: 0.9539\n",
      "Epoch 24/70\n",
      "3998/3998 [==============================] - 0s 23us/step - loss: 0.1459 - acc: 0.9561\n",
      "Epoch 25/70\n",
      "3998/3998 [==============================] - 0s 45us/step - loss: 0.1388 - acc: 0.9595\n",
      "Epoch 26/70\n",
      "3998/3998 [==============================] - 0s 27us/step - loss: 0.1320 - acc: 0.9623\n",
      "Epoch 27/70\n",
      "3998/3998 [==============================] - 0s 25us/step - loss: 0.1256 - acc: 0.9642\n",
      "Epoch 28/70\n",
      "3998/3998 [==============================] - 0s 33us/step - loss: 0.1198 - acc: 0.9661\n",
      "Epoch 29/70\n",
      "3998/3998 [==============================] - 0s 45us/step - loss: 0.1145 - acc: 0.9680\n",
      "Epoch 30/70\n",
      "3998/3998 [==============================] - 0s 73us/step - loss: 0.1092 - acc: 0.9704\n",
      "Epoch 31/70\n",
      "3998/3998 [==============================] - 0s 58us/step - loss: 0.1044 - acc: 0.9727\n",
      "Epoch 32/70\n",
      "3998/3998 [==============================] - 0s 30us/step - loss: 0.0999 - acc: 0.9734\n",
      "Epoch 33/70\n",
      "3998/3998 [==============================] - 0s 20us/step - loss: 0.0958 - acc: 0.9753\n",
      "Epoch 34/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0918 - acc: 0.9766\n",
      "Epoch 35/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0881 - acc: 0.9769\n",
      "Epoch 36/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0848 - acc: 0.9783\n",
      "Epoch 37/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0816 - acc: 0.9788\n",
      "Epoch 38/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0785 - acc: 0.9794\n",
      "Epoch 39/70\n",
      "3998/3998 [==============================] - 0s 35us/step - loss: 0.0757 - acc: 0.9803\n",
      "Epoch 40/70\n",
      "3998/3998 [==============================] - 0s 37us/step - loss: 0.0731 - acc: 0.9816\n",
      "Epoch 41/70\n",
      "3998/3998 [==============================] - 0s 40us/step - loss: 0.0705 - acc: 0.9821\n",
      "Epoch 42/70\n",
      "3998/3998 [==============================] - 0s 40us/step - loss: 0.0681 - acc: 0.9831\n",
      "Epoch 43/70\n",
      "3998/3998 [==============================] - 0s 38us/step - loss: 0.0659 - acc: 0.9836\n",
      "Epoch 44/70\n",
      "3998/3998 [==============================] - 0s 37us/step - loss: 0.0637 - acc: 0.9839\n",
      "Epoch 45/70\n",
      "3998/3998 [==============================] - 0s 18us/step - loss: 0.0617 - acc: 0.9846\n",
      "Epoch 46/70\n",
      "3998/3998 [==============================] - 0s 19us/step - loss: 0.0598 - acc: 0.9847\n",
      "Epoch 47/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0581 - acc: 0.9847\n",
      "Epoch 48/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0563 - acc: 0.9852\n",
      "Epoch 49/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0548 - acc: 0.9856\n",
      "Epoch 50/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0532 - acc: 0.9859\n",
      "Epoch 51/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0517 - acc: 0.9867\n",
      "Epoch 52/70\n",
      "3998/3998 [==============================] - 0s 31us/step - loss: 0.0503 - acc: 0.9864\n",
      "Epoch 53/70\n",
      "3998/3998 [==============================] - 0s 39us/step - loss: 0.0489 - acc: 0.9872\n",
      "Epoch 54/70\n",
      "3998/3998 [==============================] - 0s 45us/step - loss: 0.0476 - acc: 0.9872\n",
      "Epoch 55/70\n",
      "3998/3998 [==============================] - 0s 43us/step - loss: 0.0465 - acc: 0.9876\n",
      "Epoch 56/70\n",
      "3998/3998 [==============================] - 0s 43us/step - loss: 0.0453 - acc: 0.9878\n",
      "Epoch 57/70\n",
      "3998/3998 [==============================] - 0s 34us/step - loss: 0.0442 - acc: 0.9881\n",
      "Epoch 58/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0431 - acc: 0.9886\n",
      "Epoch 59/70\n",
      "3998/3998 [==============================] - 0s 23us/step - loss: 0.0421 - acc: 0.9888\n",
      "Epoch 60/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0412 - acc: 0.9890\n",
      "Epoch 61/70\n",
      "3998/3998 [==============================] - 0s 28us/step - loss: 0.0402 - acc: 0.9894\n",
      "Epoch 62/70\n",
      "3998/3998 [==============================] - 0s 21us/step - loss: 0.0393 - acc: 0.9897\n",
      "Epoch 63/70\n",
      "3998/3998 [==============================] - 0s 31us/step - loss: 0.0384 - acc: 0.9898\n",
      "Epoch 64/70\n",
      "3998/3998 [==============================] - 0s 45us/step - loss: 0.0376 - acc: 0.9902\n",
      "Epoch 65/70\n",
      "3998/3998 [==============================] - 0s 39us/step - loss: 0.0369 - acc: 0.9902\n",
      "Epoch 66/70\n",
      "3998/3998 [==============================] - 0s 40us/step - loss: 0.0361 - acc: 0.9904\n",
      "Epoch 67/70\n",
      "3998/3998 [==============================] - 0s 42us/step - loss: 0.0353 - acc: 0.9908\n",
      "Epoch 68/70\n",
      "3998/3998 [==============================] - 0s 49us/step - loss: 0.0346 - acc: 0.9905\n",
      "Epoch 69/70\n",
      "3998/3998 [==============================] - 0s 25us/step - loss: 0.0339 - acc: 0.9906\n",
      "Epoch 70/70\n",
      "3998/3998 [==============================] - 0s 22us/step - loss: 0.0332 - acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7af2143f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=nb_words, output_dim=8, input_length=input_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# print(model.summary())\n",
    "# batch = 50\n",
    "batch = 100\n",
    "model.fit(X_train, Y_train, epochs=70, batch_size=batch, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80425\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# loss, accuracy = model.evaluate(X_train, Y_train)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet is evaluated irr\n"
     ]
    }
   ],
   "source": [
    "test = \"Macron n'est pas si mal\"\n",
    "\n",
    "test_vect = vectorize_tweet(test, \"pos\", bow, input_len)\n",
    "v = np.array(test_vect['vectorized'])\n",
    "v = v.reshape((1,input_len))\n",
    "\n",
    "res = model.predict([v])[0]\n",
    "out = decode_output(res)\n",
    "print(\"tweet is evaluated \" + out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse import sample_data\n",
    "testset = sample_data(\"tw_db_prepared.data\", 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "# from note import write_emotion\n",
    "neu=[]\n",
    "irr=[]\n",
    "positives=[]\n",
    "negatives=[]\n",
    "\n",
    "for tw in testset :\n",
    "    vec = vectorize_tweet(tw,'???', bow, input_len)\n",
    "#     print(vec['text'])\n",
    "    res = model.predict(vec['vectorized'].reshape((1,input_len)))[0]\n",
    "    out = decode_output(res)\n",
    "    if out[0] == \"pos\" :\n",
    "        positives.append(tw)\n",
    "    elif out[0] == \"neu\" :\n",
    "        neu.append(tw)\n",
    "    elif out[0] == \"neg\" :\n",
    "        negatives.append(tw)\n",
    "    elif out[0] == \"irr\" :\n",
    "        irr.append(tw)\n",
    "#     print(\"tweet is evaluated \" + out[0] + \"\\n\\n\")\n",
    "\n",
    "print(len(positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merci retweet selon sondage odoxa dentsu consulting une majorité français rejettent les manifestations hebdomadaires des gilets jaunes image président république améliore vous supportez toujours les gilets jaunes giletsjaunes odoxa macron\n",
      "merci psa merci macron cet appel generosite est plus proche concessionnaire veux une peugeot \n",
      "chez les petites phrases macron sont plupart temps justes sont accord vent tourne plus plus \n",
      "les sont aussi responsables pic pollution aux particules fines les sont responsables tout est nouvelle règle emmanuel macron \n",
      "acte david tabassé par policier suis réveillé dans une mare sang via sérieux comment font ces flics pour bien vivre jusqu taper une personne invalide vénération absolue pour macron cinglés \n",
      "alex vous avez pas vous excusez vous expliquer vous faites second degré les supporters pouvoir place macron lui même est choqué vous demande des comptes directement indirectement bref vous avez comprendre vous mêmes terrible pour france\n",
      "jean françois copé est hermétique extrême droite dépend des jours jamais sombre dans tentation alliance avec nous serons plus mais émission \n",
      "plait dessine moi macron qui délivre bennala prison bord hélico plait \n",
      "avec etat spectateur désindustrialisation prise contrôle financiers des étrangers pour gvt pas rôle etat reprendre ford blanquefort gérer les aéroports intervenirdnq gestion air france klm pas avis des néerlandais etatactionnaire\n",
      "air france klm etat hollandais prend capital licenciements série grands groupes conforama carrefour fermeture usines ford ascoval vente des biens état aéroport paris française des jeux macron complice pire liquider france \n",
      "humour prémonitoire carnaval cologne met scène des gilets jaunes déboulonnant une statue emmanuel macron via \n",
      "rond points est évoquée permanance ils retrouvent dans fraternité unis comme peuple etc aurait presque les larmes aux yeux apprécie pas non plus choix des paroles macron qui ont été sélectionnées pas une seule parole sur son action mais \n",
      "certain nombre individus provoquent insultent autorité état état doit répondre suis sûr fera mais faut faire maintenant avec une fermeté extrême affirme nicolas sarkozy suivez notre direct \n",
      "quand aura plus macron clique\n",
      "autant voter pour liste macron alors électeurs depuis ans suis choqué par cette déclaration \n",
      "avis aux giletsjaunes macron est val cenis maurienne savoie quelques rond points dans coin \n",
      "bien chose que alauzet incarne est bien mépris classe absence totale ligne politique claire passe aux présidentielles soutien valls puis hamon puis macron appelle cela opportunisme politique alauzet est une imposture lui seul \n",
      "moment gvt euro béat prépare privatisation les pays bas champion libéral hésitent pas eux monter capital infligeant france une belle leçon être libéral est pas renoncer souveraineté nbf\n",
      "donc soir double ration pop corn decathlon retire son indigne hidjab course les djihadistes seront jugés sur les terres leurs massacres combat continue macron affirme pas programme retour des djihadistes \n",
      "live conférence presse avec président république irak \n",
      "vive marine lepen\n",
      "surtout oubliez pas macron démission\n",
      "une très bonne nouvelle pour adopter blockchain dans traçabilité des aliments comme font avec tfd crypto cryptocurrency cryptomonnaie \n",
      "notre président\n",
      "après peu critiquer jeux des français est critiquer dénoncer jamais être accord sur tout rien faire seulement dire cas fait quoi ensemble entends jamais sport favoris égoïsme laissé faire attendre allez dans sens vent lâche\n",
      "entre vision macron vision serais clairement plutôt côté macron suis plutôt juncker orban hollande hamon faure non vous savez droite dure conservatrice \n",
      "lci suis plutôt juncker président ppe commission européenne orban explique \n",
      "jean pierre bouquet interpelle emmanuel macrondans cadre grand débat jean pierre bouquet faisait partie groupe élus grand est conviés elysée pour transmettre président \n",
      "macron fait venir acteur cinéma américain payé pour salon agriculture vous passez côté cyril vous avez déçu\n",
      "merci psa merci macron cet appel generosite est plus proche concessionnaire veux une peugeot \n",
      "dit quoi merci macron \n",
      "mais oubliez pas lrem modem constructifs sont les leches bottes corruption européenne macron qui assomme population pour des interets banquaires autres que français encore moins humains dénués empathie pour les peuples donc pour cela sera \n",
      "zap actu polémique sur hijab decathlon macron arrêt des manifestations zapping zap actualite actu politique decathlon emmanuel macron manifestation \n",
      "bon ouf manque sommeil provoque pas vote macron chez les gens sains normaux \n",
      "giletsjaunes vos droit macron prend note lrem acte xvi \n",
      "laissé libre choix depuis son élection les mêmes convictions change pas des seul homme politique qui une véritable colonne vertébrale change pas gré vent comme mlp nda macron tant autres\n",
      "rien voir avec vision utopiste emmanuel macron europe agirait pas sortir les propos leurs contextes comme fait bien bellamy \n",
      "article dessous suis plutôt juncker président ppe commission européenne orban appartient dlf que assume son positionnement lieu toujours veuillé être flou pour tenter ratisser large \n",
      "macron avait promis ringardiser droite moderniser gauche ringardisé gauche modernisé droite député lrm jdd une fois plus président respecte pas ses promesses \n",
      "merci vous quatre gilets jaunes vous trouvé très très bien faudrait que certaines personnes regardent cette émission plutôt que regarder bfm cnews lci aux ordres macron via csa bravo pour cette résistance face répression initiés par macron\n",
      "plutôt marine que macron\n",
      "voici les intentions votes pour les européennes intentions votes vous avez vos chances larem vous laissez pas aveugler par leurs faux sondages certains organismes sondages roulent pour macron les socialistes ont disparus\n",
      "rond points est évoquée permanance ils retrouvent dans fraternité unis comme peuple etc aurait presque les larmes aux yeux apprécie pas non plus choix des paroles macron qui ont été sélectionnées pas une seule parole sur son action mais \n",
      "juste moment primaire droite vous saviez que sarko allait perdre que macron pouvait sur certains points être pire \n",
      "garantit nos concitoyens que quand les prix montent prend peu moins fiscalité semble plus pertinent certes mais quand pic prix pétrole est plateau qui dure ans notion taxe flottante plus grand sensuq https sok \n",
      "une liste musulmans pour macron rem est comme une liste gilets jaunes pour grignote \n",
      "orange popularité macron philippe remonte février selon harris interactive merci qui merci drouet and avec pilotage branquignolesque mouvement gilets jaunes une vitrine cassée point une voiture brûlée point \n",
      "viens finir lire nouveau livre peuple président suis globalement très déçue vous recommande pas gaspiller vous explique pourquoi dessous emmanuel macron macron gilets jaunes lecture grand debat national lepeupleetlepresident\n",
      "effectivement bien lire jusqu bout les auteurs précisent que france doit absolument tenir chemin réforme que président macron est train poursuivre \n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "jean françois copé est hermétique extrême droite dépend des jours jamais sombre dans tentation alliance avec nous serons plus mais \n",
      "asselineau penserait comme gaulle alors pas travaillé ces documents non plus pourtant historien politologue franco allemand alfred grosser est loin être souverainiste appelé voter macron \n",
      "france pas attendu macron pour fermer les maternités fait moins ans que les petites mater ferment \n",
      "crois que vous vous arrangez que vous voulez comprendre matin sur rtl clairement expliqué macron regardez replay\n",
      "air france klm tension monte cran macron demande une clarification haye air france klm delta eastern china paris haye\n",
      "vous avez raison\n",
      "notre macron aime europe aime pas raccomandations europe même temps rien pitoyable \n",
      "air france klm président français appelle les pays bas clarifier leurs intentions président français emmanuel macron appelé mercredi gouvernement néerlandais clarifier ses intentions après entrée surprise etat néerlandais \n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "pour contrer tandem macron pen votre pour leur donnerai jamais mon bulletin \n",
      "suis confiant dans président président emmanuel macron\n",
      "suis confiant dans président président emmanuel macron\n",
      "gironde visite surprise emmanuel macron lors grand débat féminin source france\n",
      "conseiller macron yassine belattar appelle une manifestation soutien hijab decathlon https kou \n",
      "que les français réfléchissent bien ils veulent pas mlp pouvoir nouveau duel avec macron alors ils votent pour des opposants droite gauche dès tour pour les éliminer car sachez bien front républicain marchera plus cette fois\n",
      "bonjour pourriez vous répondre ceci vous plait \n",
      "suis pas personnage voulu caricaturer affirme macron \n",
      "presse attend emmanuel macron résidence préfectorale bordeaux rencontre matin une quarantaine élus locaux dans cadre grand débat \n",
      "argument majeur candidat macron lors élection présidentielle était son expertise économique wait\n",
      "suis pas personnage voulu caricaturer affirme macron \n",
      "tout fait accord pour macron mais voter pour dupont aignan asselineau pen pour espérer changement non merci \n",
      "demander elisabeth borne poursuivre privatisation sncf étonner une société privée cherche profitabilité pour servir ses actionnaires dont etat interroge sncfnt\n"
     ]
    }
   ],
   "source": [
    "for p in positives :\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 (default, Nov 30 2018, 15:49:23) \n",
      "[GCC 8.2.1 20180831]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
